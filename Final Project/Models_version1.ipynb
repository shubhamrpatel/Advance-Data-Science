{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np \n",
    "import pandas as pd \n",
    "\n",
    "\n",
    "dataset = pd.read_csv('insurance.csv')\n",
    "X = dataset.iloc[:, :-1].values\n",
    "y = dataset.iloc[:, 6].values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Encoding categorical data\n",
    "from sklearn.preprocessing import LabelEncoder, OneHotEncoder\n",
    "labelencoder = LabelEncoder()\n",
    "X[:, 1] = labelencoder.fit_transform(X[:, 1])\n",
    "X[:, 4] = labelencoder.fit_transform(X[:, 4])\n",
    "X[:, 5] = labelencoder.fit_transform(X[:, 5])\n",
    "onehotencoder = OneHotEncoder(categorical_features = [5])\n",
    "X = onehotencoder.fit_transform(X).toarray()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Avoiding the Dummy Variable Trap\n",
    "X = X[:, 1:]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<table class=\"simpletable\">\n",
       "<caption>OLS Regression Results</caption>\n",
       "<tr>\n",
       "  <th>Dep. Variable:</th>            <td>y</td>        <th>  R-squared:         </th> <td>   0.750</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Model:</th>                   <td>OLS</td>       <th>  Adj. R-squared:    </th> <td>   0.749</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Method:</th>             <td>Least Squares</td>  <th>  F-statistic:       </th> <td>   998.1</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Date:</th>             <td>Sat, 21 Apr 2018</td> <th>  Prob (F-statistic):</th>  <td>  0.00</td>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Time:</th>                 <td>09:50:47</td>     <th>  Log-Likelihood:    </th> <td> -13551.</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>No. Observations:</th>      <td>  1338</td>      <th>  AIC:               </th> <td>2.711e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Residuals:</th>          <td>  1333</td>      <th>  BIC:               </th> <td>2.714e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Df Model:</th>              <td>     4</td>      <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Covariance Type:</th>      <td>nonrobust</td>    <th>                     </th>     <td> </td>    \n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "    <td></td>       <th>coef</th>     <th>std err</th>      <th>t</th>      <th>P>|t|</th>  <th>[0.025</th>    <th>0.975]</th>  \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>const</th> <td> -1.21e+04</td> <td>  941.984</td> <td>  -12.848</td> <td> 0.000</td> <td> -1.4e+04</td> <td>-1.03e+04</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x1</th>    <td>  257.8495</td> <td>   11.896</td> <td>   21.675</td> <td> 0.000</td> <td>  234.512</td> <td>  281.187</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x2</th>    <td>  321.8514</td> <td>   27.378</td> <td>   11.756</td> <td> 0.000</td> <td>  268.143</td> <td>  375.559</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x3</th>    <td>  473.5023</td> <td>  137.792</td> <td>    3.436</td> <td> 0.001</td> <td>  203.190</td> <td>  743.814</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>x4</th>    <td> 2.381e+04</td> <td>  411.220</td> <td>   57.904</td> <td> 0.000</td> <td>  2.3e+04</td> <td> 2.46e+04</td>\n",
       "</tr>\n",
       "</table>\n",
       "<table class=\"simpletable\">\n",
       "<tr>\n",
       "  <th>Omnibus:</th>       <td>301.480</td> <th>  Durbin-Watson:     </th> <td>   2.087</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Prob(Omnibus):</th> <td> 0.000</td>  <th>  Jarque-Bera (JB):  </th> <td> 722.157</td> \n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Skew:</th>          <td> 1.215</td>  <th>  Prob(JB):          </th> <td>1.53e-157</td>\n",
       "</tr>\n",
       "<tr>\n",
       "  <th>Kurtosis:</th>      <td> 5.654</td>  <th>  Cond. No.          </th> <td>    292.</td> \n",
       "</tr>\n",
       "</table>"
      ],
      "text/plain": [
       "<class 'statsmodels.iolib.summary.Summary'>\n",
       "\"\"\"\n",
       "                            OLS Regression Results                            \n",
       "==============================================================================\n",
       "Dep. Variable:                      y   R-squared:                       0.750\n",
       "Model:                            OLS   Adj. R-squared:                  0.749\n",
       "Method:                 Least Squares   F-statistic:                     998.1\n",
       "Date:                Sat, 21 Apr 2018   Prob (F-statistic):               0.00\n",
       "Time:                        09:50:47   Log-Likelihood:                -13551.\n",
       "No. Observations:                1338   AIC:                         2.711e+04\n",
       "Df Residuals:                    1333   BIC:                         2.714e+04\n",
       "Df Model:                           4                                         \n",
       "Covariance Type:            nonrobust                                         \n",
       "==============================================================================\n",
       "                 coef    std err          t      P>|t|      [0.025      0.975]\n",
       "------------------------------------------------------------------------------\n",
       "const       -1.21e+04    941.984    -12.848      0.000    -1.4e+04   -1.03e+04\n",
       "x1           257.8495     11.896     21.675      0.000     234.512     281.187\n",
       "x2           321.8514     27.378     11.756      0.000     268.143     375.559\n",
       "x3           473.5023    137.792      3.436      0.001     203.190     743.814\n",
       "x4          2.381e+04    411.220     57.904      0.000     2.3e+04    2.46e+04\n",
       "==============================================================================\n",
       "Omnibus:                      301.480   Durbin-Watson:                   2.087\n",
       "Prob(Omnibus):                  0.000   Jarque-Bera (JB):              722.157\n",
       "Skew:                           1.215   Prob(JB):                    1.53e-157\n",
       "Kurtosis:                       5.654   Cond. No.                         292.\n",
       "==============================================================================\n",
       "\n",
       "Warnings:\n",
       "[1] Standard Errors assume that the covariance matrix of the errors is correctly specified.\n",
       "\"\"\""
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Building the optimal model using Backward Elimination\n",
    "import statsmodels.formula.api as sm\n",
    "X = np.append(arr = np.ones((1338, 1)).astype(int), values = X, axis = 1)\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 5, 6, 7, 8]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 1, 2, 3, 4, 6, 7, 8]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 2, 3, 4, 6, 7, 8]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 2, 4, 6, 7, 8]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()\n",
    "X_opt = X[:, [0, 4, 6, 7, 8]]\n",
    "regressor_OLS = sm.OLS(endog = y, exog = X_opt).fit()\n",
    "regressor_OLS.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "X_opt = X[:, [0, 2, 3, 4, 6, 7, 8]]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Splitting X-opt into training and Split test\n",
    "from sklearn.cross_validation import train_test_split\n",
    "X_train, X_test, y_train, y_test = train_test_split(X_opt, y, test_size = 0.2, random_state = 0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "LinearRegression(copy_X=True, fit_intercept=True, n_jobs=1, normalize=False)"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Fitting Multiple Linear Regression to the Training set\n",
    "from sklearn.linear_model import LinearRegression\n",
    "regressor = LinearRegression()\n",
    "regressor.fit(X_train, y_train)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predicting the Test set results\n",
    "#We can compare y_pred and y_test to find its accuracy\n",
    "y_pred = regressor.predict(X_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([11179.78396531,  9478.43960021, 38323.79532847, 16408.17920146,\n",
       "        7036.28878939,  3837.87153244,  1436.15007609, 14507.76397291,\n",
       "        9131.84254997,  7642.04803594,  4348.54524981, 10401.03254095,\n",
       "        8794.02242961,  3787.08759217, 28064.52785452, 10706.01217353,\n",
       "       11428.61646478,  5978.97671757,  8376.22947501, 27021.75728786,\n",
       "       33785.0115461 , 14478.74114159, 11600.75786066, 32133.57489599,\n",
       "        4173.98037729,  9130.70714151,   941.58336413,  9793.96593832,\n",
       "        3759.9603479 , 10568.49019205,  9128.72005345, 40090.05779589,\n",
       "       15702.26304759, 13891.48517285, 24620.74114819,  5025.53695782,\n",
       "       12618.62128196, 30779.56304825, 33674.46414918,  3661.21699033,\n",
       "        3834.74903591,  3991.63644158, 30408.63374001, 39649.25468794,\n",
       "       27802.72192668,  5209.74250002, 10595.09645726,  7965.6045085 ,\n",
       "        3450.23945008, 10205.62630831,  5579.2804889 ,  3541.77664294,\n",
       "       33033.87405448, 38340.32817368, 16049.61764395,  7040.2672175 ,\n",
       "        5744.08298811,  9592.27259404,  8914.13990262, 11864.92672019,\n",
       "        1861.23811988, 39057.55092774, 14908.55799124, 11814.15949129,\n",
       "       13926.98895056, 14051.70950719, 25838.28860877, 32368.66013145,\n",
       "         799.75409523, 10299.42679382, 12356.18631406, 11536.61490348,\n",
       "       25253.6198308 , 15618.31503145, 11332.82561891, 12514.24605124,\n",
       "        6564.93263993,  9596.76969856, 30049.80944308, 39124.0254685 ,\n",
       "       11913.81568716, 37292.35907186,  4399.42130483,  9402.61691369,\n",
       "       34734.19340085, 28855.38848626,  8679.39819303,  5063.71223283,\n",
       "       12049.45879295, 30481.29575337,  9939.46708843, 11404.28426269,\n",
       "        8258.30167657,  8889.38116498,  8308.11100611,  7182.95994227,\n",
       "       35907.59254597, 33194.09838882,  7780.48285572, 15153.69087354,\n",
       "        4021.17042503,  8964.81073868,  6311.08359441, 31559.19814015,\n",
       "       33117.81316747,  2092.63476277,  9036.52106746,  6816.75524382,\n",
       "       14465.11574701, 37257.45539686, 10256.35272813, 10589.97996214,\n",
       "       10351.00816553, 26865.22837461, 39915.04292993,  8338.0542    ,\n",
       "         299.50423428,  9025.72206318, 15276.09781154,  9662.1673571 ,\n",
       "       35162.90263391,  7385.96064263, 16983.07399387,  9527.49591954,\n",
       "        8241.24368233,  3057.92362293, 32780.20120856, 31623.11986276,\n",
       "       39643.82383769,  5742.0543952 ,  9300.99445519,  3594.7666032 ,\n",
       "        7637.1733989 ,  8505.08175931, 31746.49421702, 29984.33274291,\n",
       "       29791.9846019 ,  8716.88189042, 32429.43545169,  3493.09846988,\n",
       "        3827.79872618, 11276.77129632, 13158.43287155, 12747.12551451,\n",
       "        5583.323348  , 15576.42079545, 14928.1855411 ,  2524.47631929,\n",
       "         157.37754964, 10724.8040594 ,  7269.38329855, 31862.30245327,\n",
       "       12262.14133802,  2337.72181888,  6596.58081255,  7849.16017028,\n",
       "        4580.28930461,  2115.89038635, 11475.94843546, 12662.05261258,\n",
       "        7137.40851772, 16399.64737587, 11939.50097606, 14118.93115341,\n",
       "        3042.7369801 ,  7163.30885251, 23117.53272925,  7450.46634422,\n",
       "        5364.49511911,  5191.91114596,  6892.67995404,  5071.09263435,\n",
       "       10124.58874121,  5384.20859504,  5738.99011488,  6643.89251564,\n",
       "        3570.36938248,  5703.2382345 , 37944.67480412,  1372.28951218,\n",
       "       12760.75090908,  9101.47351628, 13923.86220204,  5406.41350874,\n",
       "        5061.72514477, 36343.68775549,  4271.70017702,  2032.2614585 ,\n",
       "       15349.79615216, 12541.92268019, 35021.35089255,  4768.10822786,\n",
       "        5672.42245357, 31241.32683531,  6342.48475929,  2155.92928655,\n",
       "        8313.93015937,  9905.97555821,  8006.86891322,  5939.24019429,\n",
       "       13023.78436015, 38483.00681954, 13873.62703271, 28884.69015462,\n",
       "        6921.48773946, 35527.63758511,  3638.91369118, 11901.32631479,\n",
       "        9049.52018699,  6264.09640318, 11500.4983159 , 14426.940472  ,\n",
       "        5283.89091608,  4456.47083556,  7916.54136064,  1349.2695319 ,\n",
       "        7730.03264049,  4275.74303612, 12880.02552364,  4099.13294133,\n",
       "       10104.190546  ,  7054.81297465,  9291.00897996,  2255.40866907,\n",
       "       13241.47362434, 17010.17081381, 14935.59992318, 10586.21859863,\n",
       "        5293.23813807,  2236.67430365,  1938.38346888, 13387.50744776,\n",
       "       14048.21242063,  4873.69604135,  3747.68540768,  9495.61960181,\n",
       "        9840.12365425, 28165.00244517,  7524.82555419, 10332.48823225,\n",
       "        6315.25820578, 29991.06271575, 11142.54993421,  7368.08159505,\n",
       "       10369.31730489, 12386.73996931,  2878.83191732, 10997.42004594,\n",
       "        1397.97480108,  6913.46645225, 28438.76755314, 38690.05399114,\n",
       "        6359.62095339,  8181.79846685,  2394.05853474,   318.59020768,\n",
       "       10578.99572255,  4193.66969959,  5086.27927719,  2330.39274912,\n",
       "        6811.60185174, 33407.19277679, 38131.78354496, 14884.46731742,\n",
       "        8414.18970413, 16031.26081106, 32897.66288984,  9342.86453755])"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "y_pred"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_features, test_features, train_labels, test_labels = train_test_split(X, y, test_size = 0.25, random_state = 42)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.ensemble import RandomForestRegressor\n",
    "rf = RandomForestRegressor(n_estimators = 1000, random_state = 42)\n",
    "rf.fit(train_features, train_labels);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "predictions = rf.predict(test_features)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Mean Absolute Error: 2623.17 degrees.\n",
      "Accuracy: 69.91 %.\n",
      "MAE: 2623.171652847343\n",
      "MSE: 22573617.85615342\n",
      "RMSE: 4751.170156514437\n",
      "R2: 0.8503979895681671\n"
     ]
    }
   ],
   "source": [
    "# Calculate the absolute errors\n",
    "errors = abs(predictions - test_labels)\n",
    "# Print out the mean absolute error (mae)\n",
    "print('Mean Absolute Error:', round(np.mean(errors), 2), 'degrees.')\n",
    "\n",
    "# Calculate mean absolute percentage error (MAPE)\n",
    "mape = 100 * (errors / test_labels)\n",
    "# Calculate and display accuracy\n",
    "accuracy = 100 - np.mean(mape)\n",
    "print('Accuracy:', round(accuracy, 2), '%.')\n",
    "\n",
    "from sklearn import metrics\n",
    "print('MAE:', metrics.mean_absolute_error(test_labels, predictions))\n",
    "print('MSE:', metrics.mean_squared_error(test_labels, predictions))\n",
    "print('RMSE:', np.sqrt(metrics.mean_squared_error(test_labels, predictions)))\n",
    "print('R2:', metrics.r2_score(test_labels, predictions))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
